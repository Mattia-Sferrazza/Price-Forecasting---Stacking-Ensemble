{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv(r\"C:\\Users\\matti\\OneDrive\\Thesis\\Data\\FINAL_daily_sentiment_GOOG.csv\")\n",
    "sentiment[\"date\"] = pd.to_datetime(sentiment[\"date\"])\n",
    "\n",
    "price_indicators = pd.read_csv(r\"C:\\Users\\matti\\OneDrive\\Thesis\\Data\\FINAL_price_indicators.csv\")\n",
    "price_indicators[\"date\"] =  pd.to_datetime(price_indicators[\"date\"])\n",
    "\n",
    "print(f\"Sentiment Data: /n{sentiment.columns}\")\n",
    "print()\n",
    "print(f\"Price and Indicator Data: /n{price_indicators.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593958e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Data\n",
    "\n",
    "earliest_date_s = sentiment[\"date\"][0]\n",
    "latest_date_s = sentiment[\"date\"][len(sentiment) - 1]\n",
    "\n",
    "print(f\"Date for Sentiment: {earliest_date_s} - {latest_date_s}, for a total of: {len(sentiment)} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615528fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price and Indicators Data \n",
    "\n",
    "earliest_date_p = price_indicators.loc[price_indicators[\"date\"] == \"2020-01-02\", \"date\"].iloc[0]\n",
    "latest_date_p = price_indicators[\"date\"].iloc[-1]\n",
    "\n",
    "filtered = price_indicators[(price_indicators[\"date\"] >= earliest_date_p) & (price_indicators[\"date\"] <= latest_date_p)]\n",
    "\n",
    "print(f\"Date for Sentiment: {earliest_date_p} - {latest_date_p}, for a total of {len(filtered)} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter price and indicators to same range as sentiment\n",
    "final_filtered_pi = filtered[(filtered[\"date\"] >= earliest_date_s) & (filtered[\"date\"] <= latest_date_s)]\n",
    "\n",
    "#check that length is the same as sentiment\n",
    "print(f\"Price and Indicator range: {final_filtered_pi['date'].min()} - {final_filtered_pi['date'].max()}, for a total of {len(final_filtered_pi)}\")\n",
    "print(f\"Sentiment range: {earliest_date_s} - {latest_date_s}, for a total of {len(sentiment)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49750d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sentiment data also contains data for holidays, while price and indicator only has trading days which exclude holidays\n",
    "\"\"\"\n",
    "\n",
    "#So let\"s remove the holidays from the sentiment data\n",
    "#We can check this with difference:\n",
    "\n",
    "# Use pandas Index to access `.difference`\n",
    "dates_not_in_price = pd.Index(sentiment[\"date\"]).difference(pd.Index(final_filtered_pi[\"date\"]))\n",
    "\n",
    "print(dates_not_in_price)\n",
    "#These are all the dates present at the end of IndicatorData.ipynb which all correspond to a USA nationla holiday where Trading is closed\n",
    "\n",
    "#Remove these rows \n",
    "sentiment = sentiment[~sentiment[\"date\"].isin(dates_not_in_price)]\n",
    "\n",
    "dates_not_in_price2 = pd.Index(sentiment[\"date\"]).difference(pd.Index(final_filtered_pi[\"date\"]))\n",
    "\n",
    "print(dates_not_in_price2)\n",
    "print(sentiment.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df58d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check date ranges now after removing public holidays\n",
    "print(f\"Price and Indicator range: {final_filtered_pi['date'].min()} - {final_filtered_pi['date'].max()}, for a total of {len(final_filtered_pi)}\")\n",
    "print(f\"Sentiment range: {earliest_date_s} - {latest_date_s}, for a total of {len(sentiment)}\")\n",
    "\n",
    "all_dates_present = sentiment[\"date\"].isin(final_filtered_pi[\"date\"]).all()\n",
    "print(all_dates_present)\n",
    "\n",
    "all_dates_present2 = final_filtered_pi[\"date\"].isin(sentiment[\"date\"]).all()\n",
    "print(all_dates_present2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final sort to make sure and then merge and save\n",
    "\n",
    "sentiment = sentiment.sort_values(by=\"date\").reset_index(drop=True)\n",
    "final_filtered_pi = final_filtered_pi.sort_values(by=\"date\").reset_index(drop=True)\n",
    "\n",
    "merged_df = pd.merge(sentiment, final_filtered_pi, on=\"date\", how=\"inner\")\n",
    "print(f\"Merged DataFrame range: {merged_df['date'].min()} - {merged_df['date'].max()}, for a total of {len(merged_df)}\")\n",
    "\n",
    "nan_rows = merged_df[merged_df.isna().any(axis=1)]\n",
    "print(nan_rows) #The first 6 rows have NaN values since sentiment is calculate on rolling window of 7 days.\n",
    "\n",
    "#Delete these rows\n",
    "merged_df.dropna(inplace=True)\n",
    "print(merged_df.head())\n",
    "\n",
    "merged_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(r\"C:\\Users\\matti\\OneDrive\\Thesis\\Data\\AGGREGATED.csv\", index=True) #save to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
